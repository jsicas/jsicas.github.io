[
  {
    "objectID": "listas_econometria/Lista3_Resolucao_ME715.html",
    "href": "listas_econometria/Lista3_Resolucao_ME715.html",
    "title": "Lista 3 - Econometria - ME715",
    "section": "",
    "text": "\\[\n\\DeclareMathOperator{\\tr}{tr}\n\\DeclareMathOperator{\\posto}{posto}\n\\DeclareMathOperator{\\Cov}{Cov}\n\\DeclareMathOperator{\\Var}{\\mathbb{V}}\n\\DeclareMathOperator{\\bbE}{\\mathbb{E}}\n\\newcommand{\\bs}[1]{\\boldsymbol{#1}}\n\\newcommand{\\RR}{\\mathbb{R}}\n\\]\n\n\n\n\n\n\n\nQuestão 1\n\n\n\nProve que \\(\\boldsymbol M = I - X(X'X)^{-1}X'\\) é simétrica e idempotente.\n\n\nVamos provar que \\(\\bs{M}\\) é simétrica, isto é, \\(\\bs{M}' = \\bs{M}\\):\n\\[\n\\bs{M}' = (I - X(X'X)^{-1}X')' = I - X(X'X)^{-1}X' = \\bs{M}\n\\]\nVamos provar que \\(\\bs{M}\\) é idempotente, isto é, \\(\\bs{M}\\bs{M} = \\bs{M}\\):\n\\[\\begin{align*}\n  \\bs{M}\\bs{M} &= (I - X(X'X)^{-1}X') (I - X(X'X)^{-1}X')\\\\\n  &= I - X(X'X)^{-1}X' -  X(X'X)^{-1}X' + X(X'X)^{-1}X' X(X'X)^{-1}X'\\\\\n  &= I - 2 X(X'X)^{-1}X' + X(X'X)^{-1}X'\\\\\n  &= I - X(X'X)^{-1}X'\\\\\n  &= \\bs{M}\n\\end{align*}\\]\nPortanto, fica provado que \\(\\bs{M}\\) é simétrica e idempotente.\n\n\n\n\n\n\n\nQuestão 2\n\n\n\nMostre que \\(s^2 = \\displaystyle\\frac{\\hat u' \\hat u}{n-k-1}\\) é um estimador não viesado para \\(\\sigma^2\\).\n\n\n\n\n\n\n\n\nResultados auxiliares\n\n\n\n\n\n\nTeorema 1 (Esperança de forma quadrática) Seja \\(X\\) um vetor aleatório \\(n\\times 1\\) com média \\(\\mu\\) e covariância \\(\\Sigma\\) e \\(A \\in \\mathbb{R}^{n \\times n}\\) uma matriz simétrica. Então, a esperança de uma forma quadrática \\(X'AX\\) é dada por: \\[\\bbE(X'AX) = \\tr(A\\Sigma) + \\mu'A\\mu\\]\n\n\n\nProof\n\nNote que \\(X'AX\\) é uma matriz \\(1 \\times 1\\), então \\[\n\\mathbb E(X'AX) = \\bbE(\\tr(X'AX)) = \\bbE(\\tr(AXX')) = \\tr(A\\bbE(XX'))\n\\]\nAlém disso, como \\(\\Var(X) = \\bbE(XX') - \\bbE(X)\\bbE(X)' \\Rightarrow \\bbE(XX') = \\Var(X) + \\bbE(X)\\bbE(X)'\\), então\n\\[\\begin{align}\n\\bbE(X'AX) &= \\tr(A\\bbE(XX'))\\\\\n           &= \\tr(A[\\Var(X) + \\bbE(X)\\bbE(X)'])\\\\\n           &= \\tr(A(\\Sigma + \\mu\\mu'))\\\\\n           &= \\tr(A\\Sigma) + \\tr(A\\mu\\mu')\\\\\n           &= \\tr(A\\Sigma) + \\tr(\\mu'A\\mu')\\\\\n           &= \\tr(A\\Sigma) + \\mu'A\\mu\n\\end{align}\\]\n\n\nTeorema 2 (Saber and Lee - Teorema 3.1, p. 40) Suponha que \\(X\\) é uma matriz \\(n \\times p\\) de posto \\(p\\), tal que \\(H = X(X'X)^{-1}X'\\). Então,\n\n\\(H\\) e \\(I - H\\) são simétricas e idempotentes;\n\\(\\posto(I -H) = \\tr(I - H) = n - p\\);\n\\(HX = X\\).\n\n\n\n\n\nQueremos mostrar que \\(\\mathbb E(s^2) = \\displaystyle\\mathbb E\\left(\\frac{\\hat{u}'\\hat{u}}{n-k-1}\\right) = \\sigma^2\\).\nSeja \\(H = X(X'X)^{-1}X'\\) e \\(\\bs{M} = I - H\\), então, \\(\\hat{u} = Y - \\hat Y = (I - H)Y = MY\\). Além disso, sabemos que \\(\\bs{M}\\) é simétrica e idempotente, como provado na Questão 1. Assim,\n\\[\\bbE(\\hat{u}'\\hat{u}) = \\bbE(Y'M'MY) = \\bbE(Y'MMY) =\\bbE(Y'MY)\\]\nEntão, pelo Teorema 1 e Teorema 2, temos \\[\\begin{align*}\n\\bbE(Y'MY) &= \\tr(M\\sigma^2I) + (X\\beta)'MX\\beta\\\\\n           &= \\sigma^2 \\tr(M) + \\beta'X'(I - H)X\\beta\\\\\n           &= \\sigma^2 \\tr(I - H) + \\beta'X'X\\beta -\n                \\beta'X'HX\\beta\\\\\n           &= \\sigma^2 (n - (k + 1)) + \\beta'X'X\\beta -\n                \\beta'X'X\\beta\\\\\n           &= \\sigma^2(n - k - 1)\n\\end{align*}\\]\nPortanto, \\[\n\\bbE(s^2) = \\displaystyle\\bbE \\left( \\frac{\\hat{u}'\\hat{u}}{n-k-1} \\right) = \\frac{1}{n-k-1}\\bbE (Y'MY) = \\frac{\\sigma^2(n-k-1)}{n-k-1} = \\sigma^2\n\\]\n\n\n\n\n\n\n\nQuestão 3\n\n\n\nMostre que \\(R^2\\) nunca diminui quando incluimos novas variáveis no modelo.\n\n\nConsidere o modelo\n\\[\nY = X\\beta + u\n\\tag{1}\\] Além disso, considere adicionar uma ou mais novas variáveis ao modelo Eq. 1, então, temos que:\n\\[\nY = X_0 \\beta_0 + X \\beta_1 + v\n\\tag{2}\\]\nCalculando a \\(SQE\\) do modelo da Eq. 2:\n\\[\\begin{align*}\n\\hat v' \\hat v = (Y - \\hat Y)'(Y - \\hat Y)\\\\\n      &= (X\\hat\\beta + \\hat u - X_0 \\hat\\beta_0 - X\\hat\\beta_1)'(X\\hat\\beta + \\hat u - X_0 \\hat\\beta_0 - X\\hat\\beta_1)\\\\\n      &= (X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0 + \\hat u)'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0 + \\hat u)\\\\\n      &= \\underbrace{(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0)'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0)}_{A} + 2 \\hat u'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0) + \\hat u' \\hat u\\\\\n      & = A + 2 \\hat u'X (\\beta - \\hat\\beta_1) - 2\\hat u' X_0\\hat\\beta_0 + \\hat u' \\hat u\n\\end{align*}\\]\nComo provado na Lista 2, desde que \\(\\beta\\) seja estimado por OLS, então, \\(\\hat u'X = \\hat u'X_0 = 0'\\). Logo,\nLogo, \\[\\hat v' \\hat v = A + \\hat u' \\hat u\\]\nVeja que \\(A = (X (\\hat\\beta - \\hat\\beta_1) - X_0 \\hat\\beta_0)^2_2 \\Rightarrow A \\geq 0\\). Portanto,\n\\[\n\\hat v' \\hat v \\leq \\hat u' \\hat u\n\\]\nComo \\(R^2 = 1 - \\frac{SQE}{SQT}\\), temos\n\\[1 - \\frac{\\hat v' \\hat v}{SQT} \\geq 1 - \\frac{\\hat u' \\hat u}{SQT}\\]\nPortanto, adicionar preditores, não diminuirá o \\(R^2\\).\n\n\n\n\n\n\n\nQuestão 4\n\n\n\nUtilize o dataset htv, estime o modelo de regressão \\[educ = \\beta_0 + \\beta_1 motheduc + \\beta_2fatheduc + \\beta_3abil + \\beta_4 abil^2 + u\\] e interprete os resultados.\n\n\n\nRPythonJulia\n\n\n\n# package e banco de dados\nrequire(wooldridge)\ndata(htv)\n\nfit_r &lt;- lm(educ ~ motheduc + fatheduc + abil + I(abil^2), data=htv)\ncoef(fit_r)\n\n(Intercept)    motheduc    fatheduc        abil   I(abil^2) \n 8.24022643  0.19012613  0.10893866  0.40146240  0.05059901 \n\n\n\n\n\n# packages\nimport statsmodels.formula.api as smf\nimport wooldridge as woo\n\n# lendo dados\nhtv = woo.dataWoo('htv')\nhtv = r['htv']  # leitura alternativa (direto do r)\n\n# ajustando modelo\nfit_py = smf.ols(formula='educ ~ motheduc + fatheduc + abil + I(abil**2)',\n                 data=htv).fit().params\nfit_py\n\nIntercept       8.240226\nmotheduc        0.190126\nfatheduc        0.108939\nabil            0.401462\nI(abil ** 2)    0.050599\ndtype: float64\n\n\n\n\n\n# packages\nusing WooldridgeDatasets, DataFrames, Statistics, GLM\n\n# dados\nhtv = DataFrame(wooldridge(\"htv\"));\n\nfit_julia = lm(@formula(educ ~ motheduc + fatheduc + abil + abil^2), htv);\ncoeficientes = DataFrame(Beta = coefnames(fit_julia), Valor = coef(fit_julia))\n\n5×2 DataFrame\n Row │ Beta         Valor\n     │ String       Float64\n─────┼───────────────────────\n   1 │ (Intercept)  8.24023\n   2 │ motheduc     0.190126\n   3 │ fatheduc     0.108939\n   4 │ abil         0.401462\n   5 │ abil ^ 2     0.050599\n\n\n\n\n\n\n\n\n\n\n\n\nQuestão 5\n\n\n\nPove o Teorema FWL.\n\nTeorema 3 (Frisch-Waugh-Lovell) Sejam os modelos \\[\nY = X_1 \\beta_1 + X_2\\beta_2 + {u} \\qquad \\text{e} \\qquad M_1Y = M_1 X_2 \\beta_2 + \\nu\n\\] em que \\(M_1 = I - X_1 (X_1' X_1)^{-1}X_1'\\). Então,\n\n\\(\\hat\\beta_2\\) em ambas regressões são numericamente idênticos;\n\\(\\hat u\\) e \\(\\hat \\nu\\) são numericamente idênticos.\n\n\n\n\nConsidere o modelo\n\\[\nY = X\\beta + u\n\\tag{3}\\] onde \\(X\\) é uma matriz \\(n \\times p\\), \\(\\beta\\) é um vetor de dimensão \\(k \\times 1\\) e \\(u\\) é o vetor do erro aleatório de dimensão \\(n \\times 1\\). Note que \\(X\\) e \\(\\beta\\) podem ser escritos como:\n\\[\nX = \\begin{bmatrix}X_1 & X_2\\end{bmatrix} \\hspace{1cm} \\text{e} \\hspace{1cm} \\beta = \\begin{bmatrix} \\beta_1\\\\ \\beta_2 \\end{bmatrix}\n\\]\nonde \\(X_1\\) é uma matriz \\(n \\times k_1\\), \\(X_2\\) é uma matriz \\(n \\times (p - k_1)\\), \\(\\beta_1\\) é um vetor de dimensão \\(k_1 \\times 1\\) e \\(\\beta_2\\) é um vetor de dimensão \\((k - k_1) \\times 1\\). Então, o modelo da Eq. 3 pode ser escrito como\n\\[\nY = X_1\\beta_1 + X_2\\beta_2 + u\n\\]\nVamos provar que \\(\\hat \\nu\\) e \\(\\hat u\\) são numericamente identicos. Para isso considere\n\\[\nY = X_1 \\hat\\beta_1 + X_2 \\hat\\beta_2 + \\hat u\n\\tag{4}\\]\nAlém disso, sabemos (da Lista 2) que \\(X' \\hat u = \\bar 0\\), então \\[\n\\begin{bmatrix} X_1' \\\\ X_2' \\end{bmatrix} \\hat u = \\begin{bmatrix}\\bar0 \\\\ \\bar0 \\end{bmatrix} \\Rightarrow X_1' \\hat u = X_2' \\hat u = \\bar0 \\tag{5} \\label{eq-lista2}\n\\]\nMultiplicando a Eq. 4 por \\(M_1\\), temos\n\\[\\begin{align*}\nM_1 Y &= M_1X_1\\hat\\beta_1 + M_1X_2\\hat\\beta_2 + M_1\\hat u\\\\\n      &= (I - X_1(X_1' X_1)^{-1}X_1')X_1\\hat\\beta_1 + M_1X_2\\hat\\beta_2 + (I - X_1(X_1' X_1)^{-1}X_1')\\hat u\\\\\n      &= (X_1 - X_1 (X_1' X_1)^{-1}X_1'X_1) \\beta_1 + M_1X_2\\hat\\beta_2 + \\hat u - X_1(X_1' X_1)^{-1} \\underbrace{X_1'\\hat u}_{\\begin{array}{c}\\bar0\\\\\\text{(por \\eqref{eq-lista2})}\\end{array}}\\\\\n      &= M_1X_2\\hat\\beta_2 + \\hat u\n\\end{align*}\\]\nLogo,\n\\[M_1 Y = M_1X_2\\hat\\beta_2 + \\hat \\nu\\] com \\(\\hat\\nu = \\hat u\\). Portanto, fica provado que \\(\\hat\\nu\\) e \\(\\hat u\\) são numericamente identicos.\nAlém disso, note que \\(\\hat\\beta_2\\) não foi alterado, e foi possível chegar em um modelo a partir, logo, \\(\\hat\\beta_2\\) é numericamente idêntico em ambos modelos.\n\n\nReferências\nSaber A.F.G.; Lee, A.J. (2003). Linear Regression Analysis. Segunda edição. Wiley."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "jsicas.github.io",
    "section": "",
    "text": "Link da Reunião\nabout"
  },
  {
    "objectID": "scripts/ic/funcionais_agregados.html",
    "href": "scripts/ic/funcionais_agregados.html",
    "title": "Dados Funcionais Agregados",
    "section": "",
    "text": "\\[\n\\DeclareMathOperator{\\tr}{tr}\n\\DeclareMathOperator{\\posto}{posto}\n\\DeclareMathOperator{\\Cov}{Cov}\n\\DeclareMathOperator{\\V}{\\mathbb{V}}\n\\DeclareMathOperator{\\E}{\\mathbb{E}}\n\\DeclareMathOperator{\\p}{\\mathbb{P}}\n\\newcommand{\\bs}[1]{\\boldsymbol{#1}}\n\\newcommand{\\bm}[1]{\\mathbf{#1}}\n\\newcommand{\\RR}{\\mathbb{R}}\n\\newcommand{\\NN}{\\mathbb{N}}\n\\newcommand{\\norm}{\\mathcal{N}}\n\\]"
  },
  {
    "objectID": "scripts/ic/funcionais_agregados.html#dados-simulados",
    "href": "scripts/ic/funcionais_agregados.html#dados-simulados",
    "title": "Dados Funcionais Agregados",
    "section": "Dados Simulados",
    "text": "Dados Simulados\nForam utilizadas as funções Bumps e Doppler com \\(SNR=3\\) e \\(5\\) considerando \\(1024\\) pontos por curva.\n\n\nCode\n######## packages e configurações ########\nset.seed(282829)\nsetwd('C:/Users/jvsiq/Desktop/Estudo e Afins/IC - FAPESP/codigo')\n\nrequire(wavethresh)\nrequire(knitr)\nrequire(ic)\n\n######## Funções ########\nbumps &lt;- f_test()$bumps\ndoppler &lt;- f_test()$doppler\npar(mfrow=c(1,2))\nplot(bumps, type='l', main='Bumps')\nplot(doppler, type='l', main='Doppler'); par(mfrow=c(1,1))\n\n\n\n\n\n\n\n\n\n\n\\(SNR=3\\)\n\n\nCode\n# gerando banco de dados\ny1 &lt;- runif(10)  # pesos da curva 1\ny2 &lt;- 1 - y1     # pesos da curva 2\n\ny &lt;- matrix(c(y1, y2), nrow=2, byrow=T)  # pesos\nfun_agr &lt;- matrix(0, length(y1), 1024)   # observacoes\n\n# gerando amostra com snr=3\nfor (i in 1:length(y1)) fun_agr[i,] &lt;- y1[i]*bumps + y2[i]*doppler + rnorm(1024, 0, 7/3)\nplot(1, main='Amostra',xlim=c(0,1010),ylim=c(-15, 58),type='n',xlab='',ylab='')\nfor (i in 1:length(y1)) lines(fun_agr[i,], col=i)\n\n\n\n\n\n\n\n\n\n\nFrequentista\n\n\nCode\n# dominio das ondaletas\nD &lt;- apply(fun_agr, MARGIN=1, wd)                 # coeficientes empiricos\nD_shrink &lt;- sapply(D, function(x = threshold(D)) c(accessC(x, level=0), x$D))\ngamma &lt;- D_shrink %*% t(y) %*% solve(y %*% t(y))  # coeficientes de ondaletas estimados\nalpha &lt;- GenW(n=1024) %*% gamma                   # funções recuperadas\n\n# funções recuperadas\nplot(alpha[,1], type='l', col='blue', main='Bumps Recuperada'); lines(bumps, type='l')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,2], type='l', col='blue', main='Doppler Recuperada'); lines(doppler, type='l')\n\n\n\n\n\n\n\n\n\nCode\n# calculando erro\nMSE_1 &lt;- sum((alpha[,1] - bumps)^2) / length(bumps)     # MSE da fç componente 1 (bumps)\nMSE_2 &lt;- sum((alpha[,2] - doppler)^2) / length(doppler) # MSE da fç componente 2 (doppler)\nAMSE &lt;- (MSE_1 + MSE_2) / 2\n\nkable(data.frame(MSE_1, MSE_2, AMSE))\n\n\n\n\n\nMSE_1\nMSE_2\nAMSE\n\n\n\n\n2.372409\n1.765951\n2.06918\n\n\n\n\n\n\n\nBayesiano\n\n\nCode\n# dominio das ondaletas\nD_shrink_bayes &lt;- sapply(D, function(x = D) c(accessC(x, lev=0),\n                            logis_shrink(x$D, 0.8, 1, 2)))\ngamma_bayes &lt;- D_shrink_bayes %*% t(y) %*% solve(y %*% t(y))  # coefs de ondaletas estimados\nalpha_bayes &lt;- GenW(n=1024) %*% gamma_bayes                   # funções recuperadas\n\n# funcoes recuperadas pelo metodo bayesiano\nplot(alpha_bayes[,1], type='l', col='blue', main='Bumps Recuperada'); lines(bumps, type='l')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha_bayes[,2], type='l', col='blue', main='Doppler Recuperada'); lines(doppler, type='l')\n\n\n\n\n\n\n\n\n\nCode\n# calculando erro\nMSE_bayes_1 &lt;- sum((alpha_bayes[,1] - bumps)^2) / length(bumps)     # MSE da fç componente 1 (bumps)\nMSE_bayes_2 &lt;- sum((alpha_bayes[,2] - doppler)^2) / length(doppler) # MSE da fç componente 2 (doppler)\nAMSE_bayes &lt;- (MSE_bayes_1 + MSE_bayes_1) / 2\n\nkable(data.frame(MSE_bayes_1, MSE_bayes_2, AMSE_bayes))\n\n\n\n\n\nMSE_bayes_1\nMSE_bayes_2\nAMSE_bayes\n\n\n\n\n1.676771\n1.195455\n1.676771\n\n\n\n\n\n\n\nFrequentista X Bayesiano\n\n\nCode\n# comparacao entre funcoes recuperadas pelos 2 metodos\nplot(alpha[,1], type='l', col='red');lines(alpha_bayes[,1], col='blue');lines(bumps)\nlegend('topright', legend=c('Verdadeiro', 'Bayes', 'Freq'),\n       col=c('black', 'blue', 'red'), lwd=2, bty='n')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,2], type='l', col='red');lines(alpha_bayes[,2], col='blue');lines(doppler)\nlegend('topright', legend=c('Verdadeiro', 'Bayes', 'Freq'),\n       col=c('black', 'blue', 'red'), lwd=2, bty='n')\n\n\n\n\n\n\n\n\n\nCode\nkable(data.frame('Medida'=c('Bumps', 'Doppler', 'AMSE'),\n                 'Frequentista'=c(MSE_1, MSE_2, AMSE),\n                 'Bayesiano'=c(MSE_bayes_1, MSE_bayes_2, AMSE_bayes)))\n\n\n\n\n\nMedida\nFrequentista\nBayesiano\n\n\n\n\nBumps\n2.372409\n1.676771\n\n\nDoppler\n1.765951\n1.195455\n\n\nAMSE\n2.069180\n1.676771\n\n\n\n\n\n\n\n\n\\(SNR=5\\)\n\nFrequentista\n\n\nCode\n# gerando banco de dados\ny1 &lt;- runif(10)  # pesos da curva 1\ny2 &lt;- 1 - y1     # pesos da curva 2\n\ny &lt;- matrix(c(y1, y2), nrow=2, byrow=T)  # pesos\nfun_agr &lt;- matrix(0, length(y1), 1024)   # observacoes\n\n# gerando amostra com snr=5\nfor (i in 1:length(y1)) fun_agr[i,] &lt;- y1[i]*bumps + y2[i]*doppler + rnorm(1024, 0, 7/5)\nplot(1, main='Amostra',xlim=c(0,1010),ylim=c(-15, 57),type='n',xlab='',ylab='')\nfor (i in 1:length(y1)) lines(fun_agr[i,], col=i)\n\n\n\n\n\n\n\n\n\nCode\n# dominio das ondaletas\nD &lt;- apply(fun_agr, MARGIN=1, wd)                 # coeficientes empiricos\nD_shrink &lt;- sapply(D, function(x = threshold(D)) c(accessC(x, level=0), x$D))\ngamma &lt;- D_shrink %*% t(y) %*% solve(y %*% t(y))  # coeficientes de ondaletas estimados\nalpha &lt;- GenW(n=1024) %*% gamma                   # funções recuperadas\n\n# funções recuperadas\nplot(alpha[,1], type='l', col='blue', main='Bumps Recuperada'); lines(bumps, type='l')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,2], type='l', col='blue', main='Doppler Recuperada'); lines(doppler, type='l')\n\n\n\n\n\n\n\n\n\n\n\nBayesiano\n\n\nCode\n# dominio das ondaletas\nD_shrink_bayes &lt;- sapply(D, function(x = D) c(accessC(x, lev=0),\n                            logis_shrink(x$D, 0.8, 1, 2)))\ngamma_bayes &lt;- D_shrink_bayes %*% t(y) %*% solve(y %*% t(y))  # coefs de ondaletas estimados\nalpha_bayes &lt;- GenW(n=1024) %*% gamma_bayes                   # funções recuperadas\n\n# funcoes recuperadas pelo metodo bayesiano\nplot(alpha_bayes[,1], type='l', col='blue', main='Bumps Recuperada'); lines(bumps, type='l')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha_bayes[,2], type='l', col='blue', main='Doppler Recuperada'); lines(doppler, type='l')\n\n\n\n\n\n\n\n\n\nCode\n# calculando erro\nMSE_bayes_1 &lt;- sum((alpha_bayes[,1] - bumps)^2) / length(bumps)     # MSE da fç componente 1 (bumps)\nMSE_bayes_2 &lt;- sum((alpha_bayes[,2] - doppler)^2) / length(doppler) # MSE da fç componente 2 (doppler)\nAMSE_bayes &lt;- (MSE_bayes_1 + MSE_bayes_1) / 2\n\nkable(data.frame(MSE_bayes_1, MSE_bayes_2, AMSE_bayes))\n\n\n\n\n\nMSE_bayes_1\nMSE_bayes_2\nAMSE_bayes\n\n\n\n\n0.2936653\n0.6326009\n0.2936653\n\n\n\n\n\n\n\nFrequentista X Bayesiano\n\n\nCode\n# comparacao entre funcoes recuperadas pelos 2 metodos\nplot(alpha[,1], type='l', col='red');lines(alpha_bayes[,1], col='blue');lines(bumps)\nlegend('topright', legend=c('Verdadeiro', 'Bayes', 'Freq'),\n       col=c('black', 'blue', 'red'), lwd=2, bty='n')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,2], type='l', col='red');lines(alpha_bayes[,2], col='blue');lines(doppler)\nlegend('topright', legend=c('Verdadeiro', 'Bayes', 'Freq'),\n       col=c('black', 'blue', 'red'), lwd=2, bty='n')\n\n\n\n\n\n\n\n\n\nCode\nkable(data.frame('Medida'=c('Bumps', 'Doppler', 'AMSE'),\n                 'Frequentista'=c(MSE_1, MSE_2, AMSE),\n                 'Bayesiano'=c(MSE_bayes_1, MSE_bayes_2, AMSE_bayes)))\n\n\n\n\n\nMedida\nFrequentista\nBayesiano\n\n\n\n\nBumps\n2.372409\n0.2936653\n\n\nDoppler\n1.765951\n0.6326009\n\n\nAMSE\n2.069180\n0.2936653"
  },
  {
    "objectID": "scripts/ic/funcionais_agregados.html#tecator",
    "href": "scripts/ic/funcionais_agregados.html#tecator",
    "title": "Dados Funcionais Agregados",
    "section": "Tecator",
    "text": "Tecator\nConjunto de dados que contém a espectrometria da carne. Foi necessário transformar o banco de dados para um conjunto de vetores diádicos.\n\n\nCode\nrequire(fda.usc)\ndata('tecator')\n\n# Tecator\nfun_tec &lt;- tecator$absorp.fdata[,20:83]\npesos &lt;- t(tecator$y)\n\nplot(fun_tec)\n\n\n\n\n\n\n\n\n\nCode\nD &lt;- apply(fun_tec$data, MARGIN=1, wd)\nD_shrink &lt;- sapply(D, function(x = threshold(D)) c(accessC(x, level=0), x$D))\ngamma &lt;- D_shrink %*% t(pesos) %*% solve(pesos %*% t(pesos))\nalpha &lt;- GenW(n=64) %*% gamma\n\n# funções recuperadas tecator\nplot(alpha[,1], type='l', col='blue', main='Gordura')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,2], type='l', col='blue', main='Água')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,3], type='l', col='blue', main='Proteina')\n\n\n\n\n\n\n\n\n\n\n\nCode\n# utilizando alpha=0.5\ncurve(logis_shrink(x, 0.5, 0.25, 1), -3, 3, n=500)\nD &lt;- apply(fun_tec$data, MARGIN=1, wd)  # DWT\nD_shrink_bayes_5 &lt;- sapply(D, function(x = D) c(accessC(x, level=0),\n                                              logis_shrink(x$D,0.5,0.25,1)))\ngamma_bayes_5 &lt;- D_shrink_bayes_5 %*% t(pesos) %*% solve(pesos %*% t(pesos))\nalpha_bayes_5 &lt;- GenW(n=64) %*% gamma_bayes_5\n\n# utilizando alpha=0.85\ncurve(logis_shrink(x, 0.85, 0.25, 1), -3, 3, n=500, add=T, col='blue')\n\n\n\n\n\n\n\n\n\nCode\nD &lt;- apply(fun_tec$data, MARGIN=1, wd)  # DWT\nD_shrink_bayes_85 &lt;- sapply(D, function(x = D) c(accessC(x, level=0),\n                                                 logis_shrink(x$D,0.85,0.25,1)))\ngamma_bayes_85 &lt;- D_shrink_bayes_85 %*% t(pesos) %*% solve(pesos %*% t(pesos))\nalpha_bayes_85 &lt;- GenW(n=64) %*% gamma_bayes_85\n\n# Comparacao\nplot(alpha[,1], type='l', main='Gordura', col='red', ylim=c(0.039, 0.051))\nlines(alpha_bayes_5[,1], col='blue'); lines(alpha_bayes_85[,1], col='darkgreen')\nlegend('bottomright', legend=c('Bayes 50', 'Bayes 85', 'Freq'),\n       col=c('red', 'blue', 'darkgreen'), lwd=2, bty='n')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,2], type='l', main='Água', col='red', ylim=c(0.0031, 0.0188))\nlines(alpha_bayes_5[,2], col='blue'); lines(alpha_bayes_85[,2], col='darkgreen')\nlegend('bottomright', legend=c('Bayes 50', 'Bayes 85', 'Freq'),\n       col=c('red', 'blue', 'darkgreen'), lwd=2, bty='n')\n\n\n\n\n\n\n\n\n\nCode\nplot(alpha[,3], type='l', main='Proteina', col='red', ylim=c(0.085, 0.114))\nlines(alpha_bayes_5[,3], col='blue'); lines(alpha_bayes_85[,3], col='darkgreen')\nlegend('topright', legend=c('Bayes 50', 'Bayes 85', 'Freq'),\n       col=c('red', 'blue', 'darkgreen'), lwd=2, bty='n')"
  },
  {
    "objectID": "listas_econometria/Lista4_Resolucao_ME715.html",
    "href": "listas_econometria/Lista4_Resolucao_ME715.html",
    "title": "Lista 4 - Econometria - ME715",
    "section": "",
    "text": "\\[\n\\DeclareMathOperator{\\tr}{tr}\n\\DeclareMathOperator{\\posto}{posto}\n\\DeclareMathOperator{\\Cov}{Cov}\n\\DeclareMathOperator{\\V}{\\mathbb{V}}\n\\DeclareMathOperator{\\E}{\\mathbb{E}}\n\\DeclareMathOperator{\\p}{\\mathbb{P}}\n\\newcommand{\\bs}[1]{\\boldsymbol{#1}}\n\\newcommand{\\RR}{\\mathbb{R}}\n\\newcommand{\\norm}{\\mathcal{N}}\n\\]\n\n\n\n\n\n\n\nQuestão 1\n\n\n\nProve que se \\(X \\sim \\norm_p(\\mu, \\Sigma)\\), então \\((X - \\mu)'\\Sigma^{-1} (X - \\mu) \\sim \\chi^2_p\\)\n\n\n\n\n\n\n\n\nResultados auxiliares\n\n\n\n\n\n\nDefinição 1 (Distribuição Chi-quadrado) Seja \\(Z_i \\overset{i.i.d.}{\\sim} \\norm(0,1)\\), então dizemos que \\[\\sum_{i=1}^n Z_i^2 \\sim \\chi^2_n\\] segue uma distribuição Qui-quadrado com \\(n\\) graus de liberdade.\n\n\n\n\n\nTeorema 1 Seja \\(A\\) uma matriz simétrica, então seus autovalores são todos reas.\n\n\nTeorema 2 (Teorema Espectral) Seja \\(A\\) uma matriz quadrada \\(n \\times n\\) e simétrica com autovalores reais, então, temos \\(v^{(1)},\\dots,v^{(n)}\\) autovetores ortogonais. Além disso, seja \\(V=(v^{(1)}, \\dots, v^{(n)})\\) e \\(D=\\operatorname{diag}(\\lambda_1, \\dots, \\lambda_n)\\), então \\[A = VDV'\\]\n\n\n\n\nSeja \\(X \\sim \\norm_p(\\mu,\\Sigma)\\), então\n\\[\\E\\left[ \\Sigma^{-\\frac{1}{2}}(X - \\mu) \\right] = \\Sigma^{-\\frac{1}{2}}(\\E(X) - \\mu)\\] \\[\\V\\left[ \\Sigma^{-\\frac{1}{2}}(X - \\mu) \\right] = \\Sigma^{-\\frac{1}{2}} \\V(X) \\left( \\Sigma^{-\\frac{1}{2}} \\right)' = \\Sigma^{-\\frac{1}{2}}\\Sigma^{\\frac{1}{2}}\\Sigma^{\\frac{1}{2}}\\Sigma^{-\\frac{1}{2}} = I\\] Note que a a notação \\(\\Sigma^{-\\frac{1}{2}}\\) faz sentido, por \\(\\Sigma\\) ser uma matriz simétrica (Teorema 2). Logo, \\(\\Sigma^{-\\frac{1}{2}} (X - \\mu) \\sim \\norm(\\bar0, I)\\). Então, pela Definição 1,\n\\[\\left[ \\Sigma^{-\\frac{1}{2}}(X - \\mu) \\right]' \\Sigma^{-\\frac{1}{2}}(X - \\mu) = (X - \\mu)\\Sigma^{-1}(X - \\mu) \\sim \\chi^2_p\\]\n\n\n\n\n\n\n\nQuestão 2\n\n\n\nSuponha que ajustou um modelo de regressão e obteve \\(\\beta_1 = 0.56\\) e um \\(\\text{p-valor} = 0.086\\) para testar \\(H_0∶ \\beta_1 = 0 \\;\\; V.S. \\;\\; H_1: \\beta_1 \\neq 0\\). Contudo, você está interessado em testar \\(H_0∶ \\beta_1 = 0 \\;\\; V.S. \\;\\; H_1: \\beta_1 &gt; 0\\), qual seria o p-valor? Rejeitaria \\(H_0\\) a um nível se significância de \\(5\\%\\)?\n\n\nIntuição:\n\n\n\n\n\n\n\n\n\nNote, então, que \\[\\p_{H_0} (|t| &gt; |t_{obs}|) = 2 \\p_{H_0} (t &gt; |t_{obs}|) = 2 \\p_{H_0} (t &lt; - |t_{obs}|)\\] Logo, o novo p-valor é de \\(\\frac{0.086}{2} = 0.043\\). Portanto, rejeito \\(H_0\\) a favor de \\(H_1\\), a um nível de \\(5\\%\\).\n\n\n\n\n\n\n\nQuestão 3\n\n\n\nUm erro comum em muito estudos aplicados é dizer que “aceitamos” \\(H_0\\). Contudo, nós, estatísticos, preferimos dizer “não rejeitamos” \\(H_0\\) e não “aceitamos” \\(H_0\\). Discuta o motivo.\n\n\nAo fazer um teste estatístico buscamos evidências contra \\(H_0\\) e em favor de \\(H_1\\), veja que isto não é equivalente, no caso de não encontrar evidência o suficiente, a falar que \\(H_0\\) é verdadeira.\n\n\n\n\n\n\n\nQuestão 4\n\n\n\nO dataset rdchem contém informação de 32 empresas da industria química. Entre as informações coletadas, temos: rdintens (gastos com pesquisa e desenvolvimento como uma porcentagem das vendas), sales (vendas mensuradas em mlhões de dólares) e profmarg (lucros como uma porcentagem das vendas). Ajuste um modelo da forma:\n\\[rdintens = \\beta_0 + \\beta_1 \\log(sales) + \\beta_2 profmarg + u\\] assumindo que as hipóteses do modelo linear clássico acontecem.\n\nInterprete os coeficientes de \\(\\log(sales)\\).\nTeste a hipóteses de que a intensidade de P&D não varia com sales contra a alternativa de que P&D aumenta com as vendas.\nInterprete o coeficiente de profmarg, ele é economicamente grande?\nprofmarg tem um efeito estatisticamente significativo sobre rdintens?\n\n\n\n\n\n\n\n\n\nResultados auxiliares\n\n\n\n\n\n\n\n\nTabela 1: Interpretação dos tipos de modelo\n\n\n\n\n\n\n\n\n\n\n\nModelo\nV. Dependente\nV. Independente\nInterpretação \\(\\beta_1\\)\n\n\n\n\nNível-Nível\n\\(y\\)\n\\(x\\)\n\\(\\Delta y = \\beta_1 \\Delta x\\)\n\n\nNível-Log\n\\(y\\)\n\\(\\log(x)\\)\n\\(\\Delta y = \\frac{\\beta_1}{100} \\Delta_\\% x\\)\n\n\nLog-Nível\n\\(\\log(y)\\)\n\\(x\\)\n\\(\\Delta_\\% y = 100\\beta_1 \\Delta x\\)\n\n\nLog-Log\n\\(\\log(y)\\)\n\\(\\log(x)\\)\n\\(\\Delta_\\% y = \\beta_1 \\Delta_\\% x\\)\n\n\n\n\n\n\n\n\n\n\n\nInterprete os coeficientes de \\(\\log(sales)\\).\n\n\nRPythonJulia\n\n\n\n# package e banco de dados\nrequire(wooldridge)\ndata(rdchem)\n\nfit_r &lt;- lm(rdintens ~ log(sales) + profmarg, data = rdchem)\nsummary(fit_r)\n\n\nCall:\nlm(formula = rdintens ~ log(sales) + profmarg, data = rdchem)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3016 -1.2707 -0.6895  0.8785  6.0369 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.47225    1.67606   0.282    0.780\nlog(sales)   0.32135    0.21557   1.491    0.147\nprofmarg     0.05004    0.04578   1.093    0.283\n\nResidual standard error: 1.839 on 29 degrees of freedom\nMultiple R-squared:  0.09847,   Adjusted R-squared:  0.0363 \nF-statistic: 1.584 on 2 and 29 DF,  p-value: 0.2224\n\n\n\n\n\n# packages\nimport statsmodels.formula.api as smf\nimport wooldridge as woo\nimport numpy as np\n\n# lendo dados\nrdchem = woo.dataWoo('rdchem')\nrdchem = r['rdchem']  # leitura alternativa (direto do R)\n\n# ajustando modelo\nfit_py = smf.ols(formula='rdintens ~ np.log(sales) + profmarg', data=rdchem).fit()\nprint(fit_py.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               rdintens   R-squared:                       0.098\nModel:                            OLS   Adj. R-squared:                  0.036\nMethod:                 Least Squares   F-statistic:                     1.584\nDate:                qui, 24 out 2024   Prob (F-statistic):              0.222\nTime:                        01:15:22   Log-Likelihood:                -63.333\nNo. Observations:                  32   AIC:                             132.7\nDf Residuals:                      29   BIC:                             137.1\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.4723      1.676      0.282      0.780      -2.956       3.900\nnp.log(sales)     0.3213      0.216      1.491      0.147      -0.120       0.762\nprofmarg          0.0500      0.046      1.093      0.283      -0.044       0.144\n==============================================================================\nOmnibus:                       15.836   Durbin-Watson:                   1.652\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               17.790\nSkew:                           1.430   Prob(JB):                     0.000137\nKurtosis:                       5.272   Cond. No.                         70.6\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nusing WooldridgeDatasets, DataFrames, Statistics, GLM, Distributions\n\n# dados\nrdchem = DataFrame(wooldridge(\"rdchem\"));\n\nfit_julia = lm(@formula(rdintens ~ log(sales) + profmarg), rdchem);\ncoeficientes = DataFrame(Beta = coefnames(fit_julia), Valor = coef(fit_julia))\n\n3×2 DataFrame\n Row │ Beta         Valor\n     │ String       Float64\n─────┼────────────────────────\n   1 │ (Intercept)  0.472254\n   2 │ log(sales)   0.321348\n   3 │ profmarg     0.0500367\n\n\n\n\n\nA cada aumento de \\(1\\%\\) na variável sales é esperado um aumento de \\(\\frac{\\hat\\beta_1}{100} = 0.0032\\) unidades em rdintens (ver Tabela 1).\n\nTeste a hipóteses de que a intensidade de P&D não varia com sales contra a alternativa de que P&D aumenta com as vendas.\n\n\nRPythonJulia\n\n\n\nfit_r &lt;- lm(rdintens ~ sales, data=rdchem)\nsummary(fit_r)\n\n\nCall:\nlm(formula = rdintens ~ sales, data = rdchem)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0531 -1.3234 -0.5280  0.8765  6.1146 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3.064e+00  3.689e-01   8.308 2.84e-09 ***\nsales       5.318e-05  4.403e-05   1.208    0.237    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.86 on 30 degrees of freedom\nMultiple R-squared:  0.04638,   Adjusted R-squared:  0.01459 \nF-statistic: 1.459 on 1 and 30 DF,  p-value: 0.2365\n\n\n\n\n\n# ajustando modelo\nfit_py = smf.ols(formula='rdintens ~ sales', data=rdchem).fit()\nprint(fit_py.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               rdintens   R-squared:                       0.046\nModel:                            OLS   Adj. R-squared:                  0.015\nMethod:                 Least Squares   F-statistic:                     1.459\nDate:                qui, 24 out 2024   Prob (F-statistic):              0.237\nTime:                        01:15:53   Log-Likelihood:                -64.231\nNo. Observations:                  32   AIC:                             132.5\nDf Residuals:                      30   BIC:                             135.4\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      3.0643      0.369      8.308      0.000       2.311       3.818\nsales       5.318e-05    4.4e-05      1.208      0.237   -3.67e-05       0.000\n==============================================================================\nOmnibus:                       15.661   Durbin-Watson:                   1.684\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               17.224\nSkew:                           1.446   Prob(JB):                     0.000182\nKurtosis:                       5.135   Cond. No.                     9.40e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 9.4e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n\n\n\n\nusing HypothesisTests\n\nfit_julia = lm(@formula(rdintens ~ sales), rdchem);\nprintln(coeftable(fit_julia))\n\n─────────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error     t  Pr(&gt;|t|)    Lower 95%    Upper 95%\n─────────────────────────────────────────────────────────────────────────────\n(Intercept)  3.06429     0.368855    8.31    &lt;1e-08   2.31098     3.81759\nsales        5.31799e-5  4.40251e-5  1.21    0.2365  -3.67314e-5  0.000143091\n─────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nNão, note que o , por ser um teste unilateral e o R executar um teste bilateral deve ser dividido por \\(2\\). Logo, \\(\\text{p-valor} = \\frac{0.237}{2} = 0.1185\\), portanto, ao nível de significância de \\(5\\%\\), não temos evidência para rejeitar \\(H_0\\) a favor de \\(H_1\\).\n\nInterprete o coeficiente de profmarg, ele é economicamente grande?\n\nInterpretação: a cada aumento de uma unidade em profmarg é esperado, em média e mantendo todos os outros preditores fixos, um aumento de \\(0.05\\) na variável resposta rdintens. Não, ele não é economicamente grande, note que não foi significativo.\n\nprofmarg tem um efeito estatisticamente significativo sobre rdintens?\n\nNão, o efeito não é estatísticamente significativo.\n\n\n\n\n\n\n\nQuestão 5\n\n\n\nUtilizando o dataset gpa1, ajuste um modelo que explique a nota média em um curso superior (colGPA) utilizando o número de faltas às aulas por semana (skipped), horas de estudo semanais (hsGPA) e a nota do ACT (equivalente ao vestitubular). Assumindo que as hipóteses do modelo linear clássico acontecem:\n\nEncontre um intervalo de confiança \\(95\\%\\) para \\(\\beta_{hsGPA}\\).\nTeste \\(H_0∶ \\beta_{hsGPA} = 0.4 \\;\\; V.S. \\;\\; H_1∶ \\beta_{hsGPA} \\neq 0.4\\).\nVocê pode rejeitar a hipóteses \\(H_0: \\beta_{hsGPA} = 1\\) contra a alternativa bilateral (\\(H_1: \\beta_{hsGPA} \\neq 1\\))?\nTeste a hipótese nula de que, uma vez tendo sido controlado as horas de estudo semanais, o efeito de skipped e ACT sobre colGPA são, conjuntamente, nulos.\n\n\n\n\nEncontre um intervalo de confiança \\(95\\%\\) para \\(\\beta_{hsGPA}\\).\n\n\nRPythonJulia\n\n\n\nmodel_r &lt;- lm(colGPA ~ skipped + hsGPA + ACT, data = gpa1)  # ajustando modelo\nconfint(model_r, level = 0.95)  # intervalo de confianca\n\n                   2.5 %      97.5 %\n(Intercept)  0.733929519  2.04517814\nskipped     -0.134523444 -0.03170283\nhsGPA        0.226581851  0.59705049\nACT         -0.006171074  0.03561154\n\n\n\n\n\n# lendo dados\ngpa1 = woo.dataWoo('gpa1')\ngpa1 = r['gpa1']  # leitura alternativa (direto do R)\n\n# ajustando modelo\nmodel_py = smf.ols(formula='colGPA ~ skipped + hsGPA + ACT', data=gpa1).fit()\nic = model_py.conf_int()\nic.columns = ['2.5%', '97.5%']\nprint(ic)\n\n               2.5%     97.5%\nIntercept  0.733930  2.045178\nskipped   -0.134523 -0.031703\nhsGPA      0.226582  0.597050\nACT       -0.006171  0.035612\n\n\n\n\n\ngpa1 = DataFrame(wooldridge(\"gpa1\"));\nmodel_julia = lm(@formula(colGPA ~ skipped + hsGPA + ACT), gpa1);\nresults = DataFrame(\n    Term = coefnames(model_julia),\n    LowerCI = confint(model_julia)[:, 1],\n    UpperCI = confint(model_julia)[:, 2]\n)\n\n4×3 DataFrame\n Row │ Term         LowerCI      UpperCI\n     │ String       Float64      Float64\n─────┼──────────────────────────────────────\n   1 │ (Intercept)   0.73393      2.04518\n   2 │ skipped      -0.134523    -0.0317028\n   3 │ hsGPA         0.226582     0.59705\n   4 │ ACT          -0.00617107   0.0356115\n\n\n\n\n\n\nTeste \\(H_0∶ \\beta_{hsGPA} = 0.4 \\;\\; V.S. \\;\\; H_1∶ \\beta_{hsGPA} \\neq 0.4\\).\n\n\nRPythonJulia\n\n\n\ncoef_hsGPA &lt;- coef(model_r)['hsGPA']\nep_hsGPA &lt;- summary(model_r)$coefficients['hsGPA', 'Std. Error']\n\nvalor_t &lt;- (coef_hsGPA - 0.4) / ep_hsGPA\n\ngl &lt;- model_r$df.residual\np_valor &lt;- 2*pt(-abs(valor_t), gl)  # P(|t| &gt; |t_obs|) = 2 P(t &lt; -|t_obs|) \n\ncat(paste0('Valor t:', round(valor_t, 4), '\\n', 'p-valor:', round(p_valor, 4)))\n\nValor t:0.1261\np-valor:0.8998\n\n\n\n\n\nimport scipy.stats as stats\n\ncoef_hsGPA = model_py.params['hsGPA']\nep_hsGPA = model_py.bse['hsGPA']\n\nvalor_t = (coef_hsGPA - 0.4) / ep_hsGPA\n\ngl = model_py.df_resid\np_valor = 2 * stats.t.cdf(-abs(valor_t), gl)  # P(|t| &gt; |t_obs|) = 2 P(t &lt; -|t_obs|) \n\nprint(f'Valor t: {valor_t:4f} \\np-valor: {p_valor:4f}')\n\nValor t: 0.126141 \np-valor: 0.899805\n\n\n\n\n\ncoef_hsGPA = coef(model_julia)[3];\nep_hsGPA = stderror(model_julia)[3];\n\nvalor_t = (coef_hsGPA - 0.4) / ep_hsGPA;\n\ngl = 137;\n\np_valor = 2 * cdf(TDist(gl), -abs(valor_t))\n\n0.8998051414602578\n\n\n\n\n\n\nVocê pode rejeitar a hipóteses \\(H_0: \\beta_{hsGPA} = 1\\) contra a alternativa bilateral (\\(H_1: \\beta_{hsGPA} \\neq 1\\))?\n\n\nRPythonJulia\n\n\n\nvalor_t &lt;- (coef_hsGPA - 1) / ep_hsGPA\n\ngl &lt;- model_r$df.residual\np_valor &lt;- 2*pt(-abs(valor_t), gl)  # P(|t| &gt; |t_obs|) = 2 P(t &lt; -|t_obs|) \n\ncat(paste0('Valor t:', round(valor_t, 4), '\\n', 'p-valor:', round(p_valor, 4)))\n\nValor t:-6.279\np-valor:0\n\n\n\n\n\ncoef_hsGPA = model_py.params['hsGPA']\nep_hsGPA = model_py.bse['hsGPA']\n\nvalor_t = (coef_hsGPA - 1) / ep_hsGPA\n\ngl = model_py.df_resid\np_valor = 2 * stats.t.cdf(-abs(valor_t), gl)  # P(|t| &gt; |t_obs|) = 2 P(t &lt; -|t_obs|) \n\nprint(f'Valor t: {valor_t:4f} \\np-valor: {p_valor:4f}')\n\nValor t: -6.279037 \np-valor: 0.000000\n\n\n\n\n\ncoef_hsGPA = coef(model_julia)[3];\nep_hsGPA = stderror(model_julia)[3];\n\nvalor_t = (coef_hsGPA - 1) / ep_hsGPA\n\n-6.279036501519401\n\n\ngl = 137;\n\np_valor = 2 * cdf(TDist(gl), -abs(valor_t))\n\n4.204251632295657e-9\n\n\n\n\n\n\nTeste a hipótese nula de que, uma vez tendo sido controlado as horas de estudo semanais, o efeito de skipped e ACT sobre colGPA são, conjuntamente, nulos.\n\nHipóteses: \\[\nH_0: \\beta_{skipped} = \\beta_{ACT} = 0 \\quad V.S. \\quad H_1: \\beta_{skipped} \\neq 0 \\text{ ou } \\beta_{ACT} \\neq 0\n\\]\nA estatística do teste é dada por:\n\\[\nF = \\frac{(SQR_r - SQR_i)/q}{SQR_i/(n-(k+1))} \\overset{H_0}{\\sim} F_{q, n-(k+1)}\n\\] onde \\(SQR_i\\) é a soma dos resíduos do modelo irrestrito (completo) e \\(SQR_r\\) é a soma dos resíduos do modelo reduzido, isto é, o modelo irrestrito sem as preditoras que se deseja testar.\n\nRPythonJulia\n\n\n\n# Ajustando modelo completo e reduzido\nmodelo_completo &lt;- lm(colGPA ~ skipped + hsGPA + ACT, data = gpa1)\nmodelo_reduzido &lt;- lm(colGPA ~ hsGPA, data = gpa1)\nanova(modelo_reduzido, modelo_completo)\n\nAnalysis of Variance Table\n\nModel 1: colGPA ~ hsGPA\nModel 2: colGPA ~ skipped + hsGPA + ACT\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   \n1    139 16.071                                \n2    137 14.873  2    1.1981 5.5179 0.004957 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nimport statsmodels.api as sm\n\n# ajustando modelo completo e reduzido\nmodelo_completo = smf.ols(formula='colGPA ~ skipped + hsGPA + ACT', data=gpa1).fit()\nmodelo_reduzido = smf.ols(formula='colGPA ~ hsGPA', data=gpa1).fit()\nsm.stats.anova_lm(modelo_reduzido, modelo_completo)\n\n   df_resid        ssr  df_diff   ss_diff         F    Pr(&gt;F)\n0     139.0  16.071039      0.0       NaN       NaN       NaN\n1     137.0  14.872966      2.0  1.198073  5.517931  0.004957\n\n\n\n\n\nmodelo_completo = lm(@formula(colGPA ~ skipped + hsGPA + ACT), gpa1);\nmodelo_reduzido = lm(@formula(colGPA ~ hsGPA), gpa1);\nftest(modelo_reduzido.model, modelo_completo.model)\n\nF-test: 2 models fitted on 141 observations\n────────────────────────────────────────────────────────────────\n     DOF  ΔDOF      SSR     ΔSSR      R²     ΔR²      F*   p(&gt;F)\n────────────────────────────────────────────────────────────────\n[1]    3        16.0710           0.1719                        \n[2]    5     2  14.8730  -1.1981  0.2336  0.0617  5.5179  0.0050\n────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\n\n\nQuestão 6\n\n\n\nUtilize o conjunto de dados wage2 e ajuste a regressão \\[\n\\log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3 tenure + u\n\\] em que wage é o salario-hora em dolares, educ são os anos de educação formal, exper são os anos de experiência no mercado de trabalho e tenure são os anos de permanencia no emprego atual.\n\nTeste a hipótede de significância geral do modelo.\nTeste a hipótese de que um ano a mais de experiência no mercado de trabalho tem o mesmo efeito sobre \\(\\log(wage)\\) que mais um ano de permanencia no emprego atual.\nTeste a hipótese de que, controlado o número de anos de permanencia no emprego (tenure), educ e exper não tem efeito nenhum sobre \\(\\log(wage)\\).\n\n\n\n\nTeste a hipótese de significância geral do modelo.\n\n\nRPythonJulia\n\n\n\n# Ajustar o modelo de regressão\nfit_r &lt;- lm(log(wage) ~ educ + exper + tenure, data = wage2)\nsummary(fit_r)\n\n\nCall:\nlm(formula = log(wage) ~ educ + exper + tenure, data = wage2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8282 -0.2401  0.0203  0.2569  1.3400 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.496696   0.110528  49.731  &lt; 2e-16 ***\neduc        0.074864   0.006512  11.495  &lt; 2e-16 ***\nexper       0.015328   0.003370   4.549 6.10e-06 ***\ntenure      0.013375   0.002587   5.170 2.87e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3877 on 931 degrees of freedom\nMultiple R-squared:  0.1551,    Adjusted R-squared:  0.1524 \nF-statistic: 56.97 on 3 and 931 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nwage2 = woo.dataWoo('wage2')\nwage2 = r['wage2']  # leitura alternativa (direto do R)\n\nfit_py = smf.ols('np.log(wage) ~ educ + exper + tenure', data=wage2).fit()\nfit_py.summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nnp.log(wage)\nR-squared:\n0.155\n\n\nModel:\nOLS\nAdj. R-squared:\n0.152\n\n\nMethod:\nLeast Squares\nF-statistic:\n56.97\n\n\nDate:\nqui, 24 out 2024\nProb (F-statistic):\n8.12e-34\n\n\nTime:\n01:16:08\nLog-Likelihood:\n-438.84\n\n\nNo. Observations:\n935\nAIC:\n885.7\n\n\nDf Residuals:\n931\nBIC:\n905.0\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n5.4967\n0.111\n49.731\n0.000\n5.280\n5.714\n\n\neduc\n0.0749\n0.007\n11.495\n0.000\n0.062\n0.088\n\n\nexper\n0.0153\n0.003\n4.549\n0.000\n0.009\n0.022\n\n\ntenure\n0.0134\n0.003\n5.170\n0.000\n0.008\n0.018\n\n\n\n\n\n\nOmnibus:\n20.917\nDurbin-Watson:\n1.769\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n30.558\n\n\nSkew:\n-0.214\nProb(JB):\n2.31e-07\n\n\nKurtosis:\n3.775\nCond. No.\n170.\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\nwage2 = DataFrame(wooldridge(\"wage2\"));\nfit_julia = lm(@formula(log(wage) ~ educ + exper + tenure), wage2);\nftest(fit_julia.model)\n\nF-test against the null model:\nF-statistic: 56.97 on 935 observations and 3 degrees of freedom, p-value: &lt;1e-33\n\n\n\n\n\n\nTeste a hipótese de que um ano a mais de experiência no mercado de trabalho tem o mesmo efeito sobre \\(\\log(wage)\\) que mais um ano de permanencia no emprego atual.\n\n\nRPythonJulia\n\n\n\nrequire(car)\n\nfit_r &lt;- lm(log(wage) ~ educ + exper + tenure, data=wage2)\nlinearHypothesis(fit_r, 'exper - tenure = 0')\n\nLinear hypothesis test\n\nHypothesis:\nexper - tenure = 0\n\nModel 1: restricted model\nModel 2: log(wage) ~ educ + exper + tenure\n\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1    932 139.99                           \n2    931 139.96  1  0.025502 0.1696 0.6805\n\n\n\n\n\nfit_py = smf.ols(formula='np.log(wage) ~ educ + exper + tenure', data=wage2).fit()\nrestricao = 'exper - tenure = 0'\nresultado = fit_py.wald_test(restricao)\nprint(resultado)\n\n&lt;F test: F=array([[0.16963746]]), p=0.6805290172334271, df_denom=931, df_num=1&gt;\n\n\n\n\n\n# function wald_test(;Sigma, b, Terms = nothing, L = nothing, H0 = nothing, df = nothing, print_result = true)\n#     if Terms == nothing && L == nothing\n#         error(\"One of the arguments Terms or L must be used.\")\n#     end\n#     if Terms != nothing && L != nothing\n#         error(\"Only one of the arguments Terms or L must be used.\")\n#     end\n#     if Terms == nothing\n#         w = size(L)[1]\n#         Terms = (1:length(b))[(sum(L, dims = 1) .&gt; 0)[1, :]]\n#     else\n#         w = length(Terms)\n#     end\n#     if H0 == nothing\n#         H0 = fill(0, w)\n#     end\n#     if w != length(H0)\n#         error(\"Vectors of tested coefficients and of null hypothesis have different lengths\\n\")\n#     end\n#     if L == nothing\n#         L = fill(0, w, length(b))\n#         for i in 1:w\n#             L[i, Terms[i]] = 1\n#         end\n#     end\n#     f = L * b\n#     V = Sigma\n#     mat = inv(L * V * L')\n#     statistic = (f - H0)' * mat * (f - H0)\n#     p = ccdf(Chisq(w), statistic)\n#     if df == nothing\n#         res = Dict(\"chi2\" =&gt; (chi2 = statistic, df = w, P = p))\n#     else\n#         fstat = statistic/size(L)[1]\n#         df1 = size(L)[1]\n#         df2 = df\n#         res = Dict(\"chi2\" =&gt; (chi2 = statistic, df = w, P = p),\n#             \"Ftest\" =&gt; (Fstat = fstat, df1 = df1, df2 = df2, P = ccdf(FDist(df1, df2), fstat)))\n#     end\n# \n#     if print_result == true\n#         println(\"Wald test:\\n\", \"----------\\n\\n\", \"Chi-squared test:\\n\",\n#             \"X2 = \", res[\"chi2\"].chi2, \", df = \", res[\"chi2\"].df, \", P(&gt; X2) = \", res[\"chi2\"].P)\n#         if df != nothing\n#             println(\"\\nF test:\\n\",\n#             \"W = \", res[\"Ftest\"].Fstat, \", df1 = \", res[\"Ftest\"].df1, \", df2 = \", res[\"Ftest\"].df2, \", P(&gt; W) = \", res[\"Ftest\"].P)\n#         end\n#     end\n# \n#     return (Sigma = Sigma, b = b, Terms = Terms, H0 = H0, L = L, result = res, df = df)\n# end\n# \n# # include(\"wald_test.jl\")\n# fit_julia_completo = lm(@formula(log(wage) ~ educ + exper + tenure), wage2);\n# fit_julia_reduzido = lm(@formula(log(wage) ~ educ + (exper + tenure), wage2);\n# wald_test(Sigma = vcov(fit_julia_completo), b = coef(fit_julia_reduzido), Terms = 2:3)\n# ftest(fit_julia_completo.model, fit_julia_reduzido.model)\n\n\n\n\n\nTeste a hipótese de que, controlado o número de anos de permanencia no emprego (tenure), educ e exper não tem efeito nenhum sobre \\(\\log(wage)\\).\n\n\nRPythonJulia\n\n\n\nmod_completo &lt;- lm(log(wage) ~ educ + exper + tenure, data=wage2)\nmod_reduzido &lt;- lm(log(wage) ~ tenure, data=wage2)\nanova(mod_reduzido, mod_completo)\n\nAnalysis of Variance Table\n\nModel 1: log(wage) ~ tenure\nModel 2: log(wage) ~ educ + exper + tenure\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    933 159.93                                 \n2    931 139.96  2    19.973 66.43 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nmod_completo = smf.ols(formula='np.log(wage) ~ educ + exper + tenure', data=wage2).fit()\nmod_reduzido = smf.ols(formula='np.log(wage) ~ tenure', data=wage2).fit()\nsm.stats.anova_lm(mod_reduzido, mod_completo)\n\n   df_resid         ssr  df_diff   ss_diff          F        Pr(&gt;F)\n0     933.0  159.934322      0.0       NaN        NaN           NaN\n1     931.0  139.960963      2.0  19.97336  66.429944  1.074911e-27\n\n\n\n\n\nfit_julia_completo = lm(@formula(log(wage) ~ educ + exper + tenure), wage2);\nfit_julia_reduzido = lm(@formula(log(wage) ~ tenure), wage2);\nftest(fit_julia_completo.model, fit_julia_reduzido.model)\n\nF-test: 2 models fitted on 935 observations\n───────────────────────────────────────────────────────────────────\n     DOF  ΔDOF       SSR     ΔSSR      R²      ΔR²       F*   p(&gt;F)\n───────────────────────────────────────────────────────────────────\n[1]    5        139.9610           0.1551                          \n[2]    3    -2  159.9343  19.9734  0.0345  -0.1206  66.4299  &lt;1e-26\n───────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\n\n\nQuestão 7\n\n\n\nUtilize o conjunto de dados htv e ajuste a regressão \\[\neduc = \\beta_0 + \\beta_1 motheduc + \\beta_2 fatheduc + \\beta_3 abil + \\beta_4 abil^2 + u\n\\]\n\nTeste a hipóteses de que a influencia que motheduc e fatheduc exercem sobre educ é a mesma.\nTeste a hipótese de que educ está linearmente relacionado com abil contra a alternativa que diz que a relação é quadrática.\nUm colega de trabalho diz que o modelo \\(educ = \\beta_0 + \\beta_1 abil + \\beta_2 abil^2 + u\\) é suficiente, e que tanto motheduc e fatheduc não são importantes para o modelos. Faça um teste de hipóteses para rejeitar ou não rejeitar a hipótese do seu colega.\n\n\n\n\nTeste a hipóteses de que a influencia que motheduc e fatheduc exercem sobre educ é a mesma.\n\n\nRPythonJulia\n\n\n\n# require(car)\n\nfit_r &lt;- lm(educ ~ motheduc + fatheduc + abil + I(abil^2), data=htv)\nlinearHypothesis(fit_r, 'motheduc - fatheduc = 0')\n\nLinear hypothesis test\n\nHypothesis:\nmotheduc - fatheduc = 0\n\nModel 1: restricted model\nModel 2: educ ~ motheduc + fatheduc + abil + I(abil^2)\n\n  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n1   1226 3796.8                              \n2   1225 3785.2  1    11.578 3.7468 0.05314 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nhtv = woo.dataWoo('htv')\nhtv = r['htv']  # leitura alternativa (direto do R)\n\nfit_py = smf.ols('educ ~ motheduc + fatheduc + abil + I(abil**2)', data=htv).fit()\nrestricao = 'motheduc - fatheduc = 0'\nresultado = fit_py.wald_test(restricao)\n\nprint(resultado)\n\n&lt;F test: F=array([[3.74676464]]), p=0.05313970412965828, df_denom=1.22e+03, df_num=1&gt;\n\n\n\n\n\n\n\n\n\nTeste a hipótese de que educ está linearmente relacionado com abil contra a alternativa que diz que a relação é quadrática.\n\n\nRPythonJulia\n\n\n\nfit_completo &lt;- lm(educ ~ motheduc + fatheduc + abil + I(abil^2), data=htv)\nfit_reduzido &lt;- lm(educ ~ motheduc + fatheduc + abil, data=htv)\nanova(fit_completo, fit_reduzido)\n\nAnalysis of Variance Table\n\nModel 1: educ ~ motheduc + fatheduc + abil + I(abil^2)\nModel 2: educ ~ motheduc + fatheduc + abil\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)    \n1   1225 3785.2                                 \n2   1226 3900.0 -1   -114.73 37.13 1.478e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nfit_completo = smf.ols(formula='educ ~ motheduc + fatheduc + abil + I(abil**2)',\n                       data=htv).fit()\nfit_reduzido = smf.ols(formula='educ ~ motheduc + fatheduc + abil', data=htv).fit()\nsm.stats.anova_lm(fit_reduzido, fit_completo)\n\n   df_resid          ssr  df_diff     ss_diff          F        Pr(&gt;F)\n0    1226.0  3899.972622      0.0         NaN        NaN           NaN\n1    1225.0  3785.242616      1.0  114.730006  37.129524  1.478065e-09\n\n\n\n\n\nhtv = DataFrame(wooldridge(\"htv\"));\nfit_julia_completo = lm(@formula(educ ~ motheduc + fatheduc + abil + abil^2), htv);\nfit_julia_reduzido = lm(@formula(educ ~ motheduc + fatheduc + abil), htv);\nftest(fit_julia_completo.model, fit_julia_reduzido.model)\n\nF-test: 2 models fitted on 1230 observations\n─────────────────────────────────────────────────────────────────────\n     DOF  ΔDOF        SSR      ΔSSR      R²      ΔR²       F*   p(&gt;F)\n─────────────────────────────────────────────────────────────────────\n[1]    6        3785.2426            0.4444                          \n[2]    5    -1  3899.9726  114.7300  0.4275  -0.0168  37.1295  &lt;1e-08\n─────────────────────────────────────────────────────────────────────\n\n\n\n\n\n\nUm colega de trabalho diz que o modelo \\(educ = \\beta_0 + \\beta_1 abil + \\beta_2 abil^2 +𝑢\\) é suficiente, e que tanto motheduc e fatheduc não são importantes para o modelos. Faça um teste de hipóteses para rejeitar ou não rejeitar a hipótese do seu colega.\n\n\nRPythonJulia\n\n\n\nfit_completo &lt;- lm(educ ~ motheduc + fatheduc + abil + I(abil^2), data=htv)\nfit_reduzido &lt;- lm(educ ~ abil + I(abil^2), data=htv)\nanova(fit_completo, fit_reduzido)\n\nAnalysis of Variance Table\n\nModel 1: educ ~ motheduc + fatheduc + abil + I(abil^2)\nModel 2: educ ~ abil + I(abil^2)\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   1225 3785.2                                  \n2   1227 4287.9 -2   -502.63 81.333 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nfit_completo = smf.ols(formula='educ ~ motheduc + fatheduc + abil + I(abil**2)',\n                       data=htv).fit()\nfit_reduzido = smf.ols(formula='educ ~ abil + I(abil**2)', data=htv).fit()\nsm.stats.anova_lm(fit_reduzido, fit_completo)\n\n   df_resid          ssr  df_diff     ss_diff          F        Pr(&gt;F)\n0    1227.0  4287.877365      0.0         NaN        NaN           NaN\n1    1225.0  3785.242616      2.0  502.634749  81.332642  6.822776e-34\n\n\n\n\n\nfit_julia_completo = lm(@formula(educ ~ motheduc + fatheduc + abil + abil^2), htv);\nfit_julia_reduzido = lm(@formula(educ ~ abil + abil^2), htv);\nftest(fit_julia_completo.model, fit_julia_reduzido.model)\n\nF-test: 2 models fitted on 1230 observations\n─────────────────────────────────────────────────────────────────────\n     DOF  ΔDOF        SSR      ΔSSR      R²      ΔR²       F*   p(&gt;F)\n─────────────────────────────────────────────────────────────────────\n[1]    6        3785.2426            0.4444                          \n[2]    4    -2  4287.8774  502.6347  0.3706  -0.0738  81.3326  &lt;1e-33\n─────────────────────────────────────────────────────────────────────"
  }
]
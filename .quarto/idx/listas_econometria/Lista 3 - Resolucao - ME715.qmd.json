{"title":"Lista 3 - Econometria - ME715","markdown":{"yaml":{"title":"Lista 3 - Econometria - ME715","lang":"pt","crossref":{"eq-prefix":"Eq. "},"format":{"html":{"embed-resources":true,"theme":{"dark":"darkly","light":"flatly"}}}},"headingText":"Questão 1","containsRefs":false,"markdown":"\n\n::: {.hidden}\n```{css, echo=FALSE}\np {\n  text-align: justify\n}\n\n/* Ocultar o texto padrão de referência */\n.reference-cross {\n    display: none;\n}\n\n/* Estilo para mostrar apenas o número da equação */\n.equation-number {\n    color: #007BFF; /* Cor personalizada */\n    font-weight: bold; /* Negrito */\n}\n\ndetails {\n    border: 2px solid #272726; /* Borda ao redor do elemento */\n    border-radius: 5px; /* Arredondamento das bordas */\n    padding: 10px; /* Espaçamento interno */\n    margin-top: 10px; /* Espaçamento superior */\n}\n```\n\n$$\n\\DeclareMathOperator{\\tr}{tr}\n\\DeclareMathOperator{\\posto}{posto}\n\\DeclareMathOperator{\\Cov}{Cov}\n\\DeclareMathOperator{\\Var}{\\mathbb{V}}\n\\DeclareMathOperator{\\bbE}{\\mathbb{E}}\n\\newcommand{\\bs}[1]{\\boldsymbol{#1}}\n\\newcommand{\\RR}{\\mathbb{R}}\n$$\n:::\n\n::: {.callout-note icon=false}\n\nProve que $\\boldsymbol M = I - X(X'X)^{-1}X'$ é simétrica e idempotente.\n:::\n\nVamos provar que $\\bs{M}$ é simétrica, isto é, $\\bs{M}' = \\bs{M}$:\n\n\n$$\n\\bs{M}' = (I - X(X'X)^{-1}X')' = I - X(X'X)^{-1}X' = \\bs{M}\n$$\n\nVamos provar que $\\bs{M}$ é idempotente, isto é, $\\bs{M}\\bs{M} = \\bs{M}$:\n\n\\begin{align*}\n  \\bs{M}\\bs{M} &= (I - X(X'X)^{-1}X') (I - X(X'X)^{-1}X')\\\\\n  &= I - X(X'X)^{-1}X' -  X(X'X)^{-1}X' + X(X'X)^{-1}X' X(X'X)^{-1}X'\\\\\n  &= I - 2 X(X'X)^{-1}X' + X(X'X)^{-1}X'\\\\\n  &= I - X(X'X)^{-1}X'\\\\\n  &= \\bs{M}\n\\end{align*}\n\nPortanto, fica provado que $\\bs{M}$ é simétrica e idempotente.\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 2\n\nMostre que $s^2 = \\displaystyle\\frac{\\hat u' \\hat u}{n-k-1}$ é um estimador não viesado para $\\sigma^2$.\n:::\n\n::: {.callout-tip}\n# Resultados auxiliares\n\n::: {#thm-esp_forma_quadratica}\n\n# esperança de forma quadrática\n\nSeja $X$ um vetor aleatório $n\\times 1$ com média $\\mu$ e covariância $\\Sigma$ e $A \\in \\mathbb{R}^{n \\times n}$ uma matriz simétrica. Então, a esperança de uma forma quadrática $X'AX$ é dada por:\n$$\\bbE(X'AX) = \\tr(A\\Sigma) + \\mu'A\\mu$$\n:::\n\n<details>\n<summary> Proof </summary>\nNote que $X'AX$ é uma matriz $1 \\times 1$, então\n$$\n\\mathbb E(X'AX) = \\bbE(\\tr(X'AX)) = \\bbE(\\tr(AXX')) = \\tr(A\\bbE(XX'))\n$$\n\nAlém disso, como $\\Var(X) = \\bbE(XX') - \\bbE(X)\\bbE(X)' \\Rightarrow \\bbE(XX') = \\Var(X) + \\bbE(X)\\bbE(X)'$, então\n\n\\begin{align}\n\\bbE(X'AX) &= \\tr(A\\bbE(XX'))\\\\\n           &= \\tr(A[\\Var(X) + \\bbE(X)\\bbE(X)'])\\\\\n           &= \\tr(A(\\Sigma + \\mu\\mu'))\\\\\n           &= \\tr(A\\Sigma) + \\tr(A\\mu\\mu')\\\\\n           &= \\tr(A\\Sigma) + \\tr(\\mu'A\\mu')\\\\\n           &= \\tr(A\\Sigma) + \\mu'A\\mu\n\\end{align}\n</details>\n\n\n::: {#thm-saber_lee}\n## Saber and Lee - Teorema 3.1, p. 40\n\nSuponha que $X$ é uma matriz $n \\times p$ de posto $p$, tal que $H = X(X'X)^{-1}X'$. Então,\n\n  1. $H$ e $I - H$ são simétricas e idempotentes;\n  1. $\\posto(I -H) = \\tr(I - H) = n - p$;\n  1. $HX = X$.\n\n:::\n:::\n\n\nQueremos mostrar que $\\mathbb E(s^2) = \\displaystyle\\mathbb E\\left(\\frac{\\hat{u}'\\hat{u}}{n-k-1}\\right) = \\sigma^2$.\n\nSeja $H = X(X'X)^{-1}X'$ e $\\bs{M} = I - H$, então, $\\hat{u} = Y - \\hat Y = (I - H)Y = MY$. Além disso, sabemos que $\\bs{M}$ é simétrica e idempotente, como provado na Questão 1. Assim,\n\n$$\\bbE(\\hat{u}'\\hat{u}) = \\bbE(Y'M'MY) = \\bbE(Y'MMY) =\\bbE(Y'MY)$$\n\nEntão, pelo @thm-esp_forma_quadratica e @thm-saber_lee, temos\n\\begin{align*}\n\\bbE(Y'MY) &= \\tr(M\\sigma^2I) + (X\\beta)'MX\\beta\\\\\n           &= \\sigma^2 \\tr(M) + \\beta'X'(I - H)X\\beta\\\\\n           &= \\sigma^2 \\tr(I - H) + \\beta'X'X\\beta -\n                \\beta'X'HX\\beta\\\\\n           &= \\sigma^2 (n - (k + 1)) + \\beta'X'X\\beta -\n                \\beta'X'X\\beta\\\\\n           &= \\sigma^2(n - k - 1)\n\\end{align*}\n\n\nPortanto,\n$$\n\\bbE(s^2) = \\displaystyle\\bbE \\left( \\frac{\\hat{u}'\\hat{u}}{n-k-1} \\right) = \\frac{1}{n-k-1}\\bbE (Y'MY) = \\frac{\\sigma^2(n-k-1)}{n-k-1} = \\sigma^2\n$$\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 3\n\nMostre que $R^2$ nunca diminui quando incluimos novas variáveis no modelo.\n:::\n\nConsidere o modelo\n\n$$ \nY = X\\beta + u\n$$ {#eq-Q3_mod1}\nAlém disso, considere adicionar uma ou mais novas variáveis ao modelo @eq-Q3_mod1, então, temos que:\n\n$$\nY = X_0 \\beta_0 + X \\beta_1 + v\n$$ {#eq-Q3_mod2}\n\nCalculando a $SQE$ do modelo da @eq-Q3_mod2:\n\n\\begin{align*}\n\\hat v' \\hat v = (Y - \\hat Y)'(Y - \\hat Y)\\\\\n      &= (X\\hat\\beta + \\hat u - X_0 \\hat\\beta_0 - X\\hat\\beta_1)'(X\\hat\\beta + \\hat u - X_0 \\hat\\beta_0 - X\\hat\\beta_1)\\\\\n      &= (X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0 + \\hat u)'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0 + \\hat u)\\\\\n      &= \\underbrace{(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0)'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0)}_{A} + 2 \\hat u'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0) + \\hat u' \\hat u\\\\\n      & = A + 2 \\hat u'X (\\beta - \\hat\\beta_1) - 2\\hat u' X_0\\hat\\beta_0 + \\hat u' \\hat u\n\\end{align*}\n\nComo provado na Lista 2, desde que $\\beta$ seja estimado por OLS, então, $\\hat u'X = \\hat u'X_0 = 0'$. Logo,\n\nLogo,\n$$\\hat v' \\hat v = A + \\hat u' \\hat u$$\n\nVeja que $A = (X (\\hat\\beta - \\hat\\beta_1) - X_0 \\hat\\beta_0)^2_2 \\Rightarrow A \\geq 0$. Portanto,\n\n$$\n\\hat v' \\hat v \\leq \\hat u' \\hat u\n$$\n\nComo $R^2 = 1 - \\frac{SQE}{SQT}$, temos\n\n$$1 - \\frac{\\hat v' \\hat v}{SQT} \\geq 1 - \\frac{\\hat u' \\hat u}{SQT}$$\n\nPortanto, adicionar preditores, não diminuirá o $R^2$.\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 4\n\nUtilize o *dataset* `htv`, estime o modelo de regressão\n$$educ = \\beta_0 + \\beta_1 motheduc + \\beta_2fatheduc + \\beta_3abil + \\beta_4 abil^2 + u$$\ne interprete os resultados.\n:::\n\n```{r, include=F}\n# configurações para utilziar Python e Julia\nrequire(JuliaCall)\nrequire(reticulate)\n```\n\n::: {.panel-tabset}\n\n## R\n```{r, warning=F, message=F}\n# package e banco de dados\nrequire(wooldridge)\ndata(htv)\n\nfit_r <- lm(educ ~ motheduc + fatheduc + abil + I(abil^2), data=htv)\ncoef(fit_r)\n```\n\n\n## Python\n```{python}\n# packages\nimport statsmodels.formula.api as smf\nimport wooldridge as woo\n\n# lendo dados\nhtv = woo.dataWoo('htv')\nhtv = r['htv']  # leitura alternativa (direto do r)\n\n# ajustando modelo\nfit_py = smf.ols(formula='educ ~ motheduc + fatheduc + abil + I(abil**2)',\n                 data=htv).fit().params\nfit_py\n```\n\n\n## Julia\n```{julia}\n# packages\nusing WooldridgeDatasets, DataFrames, Statistics, GLM\n\n# dados\nhtv = DataFrame(wooldridge(\"htv\"));\n\nfit_julia = lm(@formula(educ ~ motheduc + fatheduc + abil + abil^2), htv);\ncoeficientes = DataFrame(Beta = coefnames(fit_julia), Valor = coef(fit_julia))\n```\n\n:::\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 5\n\nPove o Teorema FWL.\n\n\n::: {#thm-fwl}\n## Frisch-Waugh-Lovell\n\nSejam os modelos\n$$\nY = X_1 \\beta_1 + X_2\\beta_2 + {u} \\qquad \\text{e} \\qquad M_1Y = M_1 X_2 \\beta_2 + \\nu\n$$\nem que $M_1 = I - X_1 (X_1' X_1)^{-1}X_1'$. Então,\n\n1. $\\hat\\beta_2$ em ambas regressões são numericamente idênticos;\n1. $\\hat u$ e $\\hat \\nu$ são numericamente idênticos.\n:::\n:::\n\nConsidere o modelo\n\n$$\nY = X\\beta + u\n$$ {#eq-modelo}\nonde $X$ é uma matriz $n \\times p$, $\\beta$ é um vetor de dimensão $k \\times 1$ e $u$ é o vetor do erro aleatório de dimensão $n \\times 1$. Note que $X$ e $\\beta$ podem ser escritos como:\n\n$$\nX = \\begin{bmatrix}X_1 & X_2\\end{bmatrix} \\hspace{1cm} \\text{e} \\hspace{1cm} \\beta = \\begin{bmatrix} \\beta_1\\\\ \\beta_2 \\end{bmatrix}\n$$\n\nonde $X_1$ é uma matriz $n \\times k_1$, $X_2$ é uma matriz $n \\times (p - k_1)$, $\\beta_1$ é um vetor de dimensão $k_1 \\times 1$ e $\\beta_2$ é um vetor de dimensão $(k - k_1) \\times 1$. Então, o modelo da @eq-modelo pode ser escrito como\n\n$$\nY = X_1\\beta_1 + X_2\\beta_2 + u \n$$\n\nVamos provar que $\\hat \\nu$ e $\\hat u$ são numericamente identicos. Para isso considere\n\n$$\nY = X_1 \\hat\\beta_1 + X_2 \\hat\\beta_2 + \\hat u \n$$ {#eq-obs}\n\nAlém disso, sabemos (da Lista 2) que $X' \\hat u = \\bar 0$, então\n$$\n\\begin{bmatrix} X_1' \\\\ X_2' \\end{bmatrix} \\hat u = \\begin{bmatrix}\\bar0 \\\\ \\bar0 \\end{bmatrix} \\Rightarrow X_1' \\hat u = X_2' \\hat u = \\bar0 \\tag{5} \\label{eq-lista2}\n$$\n\nMultiplicando a @eq-obs por $M_1$, temos\n\n\\begin{align*}\nM_1 Y &= M_1X_1\\hat\\beta_1 + M_1X_2\\hat\\beta_2 + M_1\\hat u\\\\\n      &= (I - X_1(X_1' X_1)^{-1}X_1')X_1\\hat\\beta_1 + M_1X_2\\hat\\beta_2 + (I - X_1(X_1' X_1)^{-1}X_1')\\hat u\\\\\n      &= (X_1 - X_1 (X_1' X_1)^{-1}X_1'X_1) \\beta_1 + M_1X_2\\hat\\beta_2 + \\hat u - X_1(X_1' X_1)^{-1} \\underbrace{X_1'\\hat u}_{\\begin{array}{c}\\bar0\\\\\\text{(por \\eqref{eq-lista2})}\\end{array}}\\\\\n      &= M_1X_2\\hat\\beta_2 + \\hat u\n\\end{align*}\n\nLogo,\n\n$$M_1 Y = M_1X_2\\hat\\beta_2 + \\hat \\nu$$\ncom $\\hat\\nu = \\hat u$. Portanto, fica provado que $\\hat\\nu$ e $\\hat u$ são numericamente identicos.\n\nAlém disso, note que $\\hat\\beta_2$ não foi alterado, e foi possível chegar em um modelo a partir, logo, $\\hat\\beta_2$ é numericamente idêntico em ambos modelos.\n\n<br><br>\n\n\n# Referências\n\nSaber A.F.G.; Lee, A.J. (2003). *Linear Regression Analysis*. Segunda edição. Wiley.\n\n","srcMarkdownNoYaml":"\n\n::: {.hidden}\n```{css, echo=FALSE}\np {\n  text-align: justify\n}\n\n/* Ocultar o texto padrão de referência */\n.reference-cross {\n    display: none;\n}\n\n/* Estilo para mostrar apenas o número da equação */\n.equation-number {\n    color: #007BFF; /* Cor personalizada */\n    font-weight: bold; /* Negrito */\n}\n\ndetails {\n    border: 2px solid #272726; /* Borda ao redor do elemento */\n    border-radius: 5px; /* Arredondamento das bordas */\n    padding: 10px; /* Espaçamento interno */\n    margin-top: 10px; /* Espaçamento superior */\n}\n```\n\n$$\n\\DeclareMathOperator{\\tr}{tr}\n\\DeclareMathOperator{\\posto}{posto}\n\\DeclareMathOperator{\\Cov}{Cov}\n\\DeclareMathOperator{\\Var}{\\mathbb{V}}\n\\DeclareMathOperator{\\bbE}{\\mathbb{E}}\n\\newcommand{\\bs}[1]{\\boldsymbol{#1}}\n\\newcommand{\\RR}{\\mathbb{R}}\n$$\n:::\n\n::: {.callout-note icon=false}\n# Questão 1\n\nProve que $\\boldsymbol M = I - X(X'X)^{-1}X'$ é simétrica e idempotente.\n:::\n\nVamos provar que $\\bs{M}$ é simétrica, isto é, $\\bs{M}' = \\bs{M}$:\n\n\n$$\n\\bs{M}' = (I - X(X'X)^{-1}X')' = I - X(X'X)^{-1}X' = \\bs{M}\n$$\n\nVamos provar que $\\bs{M}$ é idempotente, isto é, $\\bs{M}\\bs{M} = \\bs{M}$:\n\n\\begin{align*}\n  \\bs{M}\\bs{M} &= (I - X(X'X)^{-1}X') (I - X(X'X)^{-1}X')\\\\\n  &= I - X(X'X)^{-1}X' -  X(X'X)^{-1}X' + X(X'X)^{-1}X' X(X'X)^{-1}X'\\\\\n  &= I - 2 X(X'X)^{-1}X' + X(X'X)^{-1}X'\\\\\n  &= I - X(X'X)^{-1}X'\\\\\n  &= \\bs{M}\n\\end{align*}\n\nPortanto, fica provado que $\\bs{M}$ é simétrica e idempotente.\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 2\n\nMostre que $s^2 = \\displaystyle\\frac{\\hat u' \\hat u}{n-k-1}$ é um estimador não viesado para $\\sigma^2$.\n:::\n\n::: {.callout-tip}\n# Resultados auxiliares\n\n::: {#thm-esp_forma_quadratica}\n\n# esperança de forma quadrática\n\nSeja $X$ um vetor aleatório $n\\times 1$ com média $\\mu$ e covariância $\\Sigma$ e $A \\in \\mathbb{R}^{n \\times n}$ uma matriz simétrica. Então, a esperança de uma forma quadrática $X'AX$ é dada por:\n$$\\bbE(X'AX) = \\tr(A\\Sigma) + \\mu'A\\mu$$\n:::\n\n<details>\n<summary> Proof </summary>\nNote que $X'AX$ é uma matriz $1 \\times 1$, então\n$$\n\\mathbb E(X'AX) = \\bbE(\\tr(X'AX)) = \\bbE(\\tr(AXX')) = \\tr(A\\bbE(XX'))\n$$\n\nAlém disso, como $\\Var(X) = \\bbE(XX') - \\bbE(X)\\bbE(X)' \\Rightarrow \\bbE(XX') = \\Var(X) + \\bbE(X)\\bbE(X)'$, então\n\n\\begin{align}\n\\bbE(X'AX) &= \\tr(A\\bbE(XX'))\\\\\n           &= \\tr(A[\\Var(X) + \\bbE(X)\\bbE(X)'])\\\\\n           &= \\tr(A(\\Sigma + \\mu\\mu'))\\\\\n           &= \\tr(A\\Sigma) + \\tr(A\\mu\\mu')\\\\\n           &= \\tr(A\\Sigma) + \\tr(\\mu'A\\mu')\\\\\n           &= \\tr(A\\Sigma) + \\mu'A\\mu\n\\end{align}\n</details>\n\n\n::: {#thm-saber_lee}\n## Saber and Lee - Teorema 3.1, p. 40\n\nSuponha que $X$ é uma matriz $n \\times p$ de posto $p$, tal que $H = X(X'X)^{-1}X'$. Então,\n\n  1. $H$ e $I - H$ são simétricas e idempotentes;\n  1. $\\posto(I -H) = \\tr(I - H) = n - p$;\n  1. $HX = X$.\n\n:::\n:::\n\n\nQueremos mostrar que $\\mathbb E(s^2) = \\displaystyle\\mathbb E\\left(\\frac{\\hat{u}'\\hat{u}}{n-k-1}\\right) = \\sigma^2$.\n\nSeja $H = X(X'X)^{-1}X'$ e $\\bs{M} = I - H$, então, $\\hat{u} = Y - \\hat Y = (I - H)Y = MY$. Além disso, sabemos que $\\bs{M}$ é simétrica e idempotente, como provado na Questão 1. Assim,\n\n$$\\bbE(\\hat{u}'\\hat{u}) = \\bbE(Y'M'MY) = \\bbE(Y'MMY) =\\bbE(Y'MY)$$\n\nEntão, pelo @thm-esp_forma_quadratica e @thm-saber_lee, temos\n\\begin{align*}\n\\bbE(Y'MY) &= \\tr(M\\sigma^2I) + (X\\beta)'MX\\beta\\\\\n           &= \\sigma^2 \\tr(M) + \\beta'X'(I - H)X\\beta\\\\\n           &= \\sigma^2 \\tr(I - H) + \\beta'X'X\\beta -\n                \\beta'X'HX\\beta\\\\\n           &= \\sigma^2 (n - (k + 1)) + \\beta'X'X\\beta -\n                \\beta'X'X\\beta\\\\\n           &= \\sigma^2(n - k - 1)\n\\end{align*}\n\n\nPortanto,\n$$\n\\bbE(s^2) = \\displaystyle\\bbE \\left( \\frac{\\hat{u}'\\hat{u}}{n-k-1} \\right) = \\frac{1}{n-k-1}\\bbE (Y'MY) = \\frac{\\sigma^2(n-k-1)}{n-k-1} = \\sigma^2\n$$\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 3\n\nMostre que $R^2$ nunca diminui quando incluimos novas variáveis no modelo.\n:::\n\nConsidere o modelo\n\n$$ \nY = X\\beta + u\n$$ {#eq-Q3_mod1}\nAlém disso, considere adicionar uma ou mais novas variáveis ao modelo @eq-Q3_mod1, então, temos que:\n\n$$\nY = X_0 \\beta_0 + X \\beta_1 + v\n$$ {#eq-Q3_mod2}\n\nCalculando a $SQE$ do modelo da @eq-Q3_mod2:\n\n\\begin{align*}\n\\hat v' \\hat v = (Y - \\hat Y)'(Y - \\hat Y)\\\\\n      &= (X\\hat\\beta + \\hat u - X_0 \\hat\\beta_0 - X\\hat\\beta_1)'(X\\hat\\beta + \\hat u - X_0 \\hat\\beta_0 - X\\hat\\beta_1)\\\\\n      &= (X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0 + \\hat u)'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0 + \\hat u)\\\\\n      &= \\underbrace{(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0)'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0)}_{A} + 2 \\hat u'(X (\\hat\\beta - \\hat\\beta_1) - X_0\\hat\\beta_0) + \\hat u' \\hat u\\\\\n      & = A + 2 \\hat u'X (\\beta - \\hat\\beta_1) - 2\\hat u' X_0\\hat\\beta_0 + \\hat u' \\hat u\n\\end{align*}\n\nComo provado na Lista 2, desde que $\\beta$ seja estimado por OLS, então, $\\hat u'X = \\hat u'X_0 = 0'$. Logo,\n\nLogo,\n$$\\hat v' \\hat v = A + \\hat u' \\hat u$$\n\nVeja que $A = (X (\\hat\\beta - \\hat\\beta_1) - X_0 \\hat\\beta_0)^2_2 \\Rightarrow A \\geq 0$. Portanto,\n\n$$\n\\hat v' \\hat v \\leq \\hat u' \\hat u\n$$\n\nComo $R^2 = 1 - \\frac{SQE}{SQT}$, temos\n\n$$1 - \\frac{\\hat v' \\hat v}{SQT} \\geq 1 - \\frac{\\hat u' \\hat u}{SQT}$$\n\nPortanto, adicionar preditores, não diminuirá o $R^2$.\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 4\n\nUtilize o *dataset* `htv`, estime o modelo de regressão\n$$educ = \\beta_0 + \\beta_1 motheduc + \\beta_2fatheduc + \\beta_3abil + \\beta_4 abil^2 + u$$\ne interprete os resultados.\n:::\n\n```{r, include=F}\n# configurações para utilziar Python e Julia\nrequire(JuliaCall)\nrequire(reticulate)\n```\n\n::: {.panel-tabset}\n\n## R\n```{r, warning=F, message=F}\n# package e banco de dados\nrequire(wooldridge)\ndata(htv)\n\nfit_r <- lm(educ ~ motheduc + fatheduc + abil + I(abil^2), data=htv)\ncoef(fit_r)\n```\n\n\n## Python\n```{python}\n# packages\nimport statsmodels.formula.api as smf\nimport wooldridge as woo\n\n# lendo dados\nhtv = woo.dataWoo('htv')\nhtv = r['htv']  # leitura alternativa (direto do r)\n\n# ajustando modelo\nfit_py = smf.ols(formula='educ ~ motheduc + fatheduc + abil + I(abil**2)',\n                 data=htv).fit().params\nfit_py\n```\n\n\n## Julia\n```{julia}\n# packages\nusing WooldridgeDatasets, DataFrames, Statistics, GLM\n\n# dados\nhtv = DataFrame(wooldridge(\"htv\"));\n\nfit_julia = lm(@formula(educ ~ motheduc + fatheduc + abil + abil^2), htv);\ncoeficientes = DataFrame(Beta = coefnames(fit_julia), Valor = coef(fit_julia))\n```\n\n:::\n\n<br><br>\n\n\n::: {.callout-note icon=false}\n# Questão 5\n\nPove o Teorema FWL.\n\n\n::: {#thm-fwl}\n## Frisch-Waugh-Lovell\n\nSejam os modelos\n$$\nY = X_1 \\beta_1 + X_2\\beta_2 + {u} \\qquad \\text{e} \\qquad M_1Y = M_1 X_2 \\beta_2 + \\nu\n$$\nem que $M_1 = I - X_1 (X_1' X_1)^{-1}X_1'$. Então,\n\n1. $\\hat\\beta_2$ em ambas regressões são numericamente idênticos;\n1. $\\hat u$ e $\\hat \\nu$ são numericamente idênticos.\n:::\n:::\n\nConsidere o modelo\n\n$$\nY = X\\beta + u\n$$ {#eq-modelo}\nonde $X$ é uma matriz $n \\times p$, $\\beta$ é um vetor de dimensão $k \\times 1$ e $u$ é o vetor do erro aleatório de dimensão $n \\times 1$. Note que $X$ e $\\beta$ podem ser escritos como:\n\n$$\nX = \\begin{bmatrix}X_1 & X_2\\end{bmatrix} \\hspace{1cm} \\text{e} \\hspace{1cm} \\beta = \\begin{bmatrix} \\beta_1\\\\ \\beta_2 \\end{bmatrix}\n$$\n\nonde $X_1$ é uma matriz $n \\times k_1$, $X_2$ é uma matriz $n \\times (p - k_1)$, $\\beta_1$ é um vetor de dimensão $k_1 \\times 1$ e $\\beta_2$ é um vetor de dimensão $(k - k_1) \\times 1$. Então, o modelo da @eq-modelo pode ser escrito como\n\n$$\nY = X_1\\beta_1 + X_2\\beta_2 + u \n$$\n\nVamos provar que $\\hat \\nu$ e $\\hat u$ são numericamente identicos. Para isso considere\n\n$$\nY = X_1 \\hat\\beta_1 + X_2 \\hat\\beta_2 + \\hat u \n$$ {#eq-obs}\n\nAlém disso, sabemos (da Lista 2) que $X' \\hat u = \\bar 0$, então\n$$\n\\begin{bmatrix} X_1' \\\\ X_2' \\end{bmatrix} \\hat u = \\begin{bmatrix}\\bar0 \\\\ \\bar0 \\end{bmatrix} \\Rightarrow X_1' \\hat u = X_2' \\hat u = \\bar0 \\tag{5} \\label{eq-lista2}\n$$\n\nMultiplicando a @eq-obs por $M_1$, temos\n\n\\begin{align*}\nM_1 Y &= M_1X_1\\hat\\beta_1 + M_1X_2\\hat\\beta_2 + M_1\\hat u\\\\\n      &= (I - X_1(X_1' X_1)^{-1}X_1')X_1\\hat\\beta_1 + M_1X_2\\hat\\beta_2 + (I - X_1(X_1' X_1)^{-1}X_1')\\hat u\\\\\n      &= (X_1 - X_1 (X_1' X_1)^{-1}X_1'X_1) \\beta_1 + M_1X_2\\hat\\beta_2 + \\hat u - X_1(X_1' X_1)^{-1} \\underbrace{X_1'\\hat u}_{\\begin{array}{c}\\bar0\\\\\\text{(por \\eqref{eq-lista2})}\\end{array}}\\\\\n      &= M_1X_2\\hat\\beta_2 + \\hat u\n\\end{align*}\n\nLogo,\n\n$$M_1 Y = M_1X_2\\hat\\beta_2 + \\hat \\nu$$\ncom $\\hat\\nu = \\hat u$. Portanto, fica provado que $\\hat\\nu$ e $\\hat u$ são numericamente identicos.\n\nAlém disso, note que $\\hat\\beta_2$ não foi alterado, e foi possível chegar em um modelo a partir, logo, $\\hat\\beta_2$ é numericamente idêntico em ambos modelos.\n\n<br><br>\n\n\n# Referências\n\nSaber A.F.G.; Lee, A.J. (2003). *Linear Regression Analysis*. Segunda edição. Wiley.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"embed-resources":true,"output-file":"Lista 3 - Resolucao - ME715.html"},"language":{"toc-title-document":"Índice","toc-title-website":"Nesta página","related-formats-title":"Outros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fonte","other-links-title":"Outros Links","code-links-title":"Ligações de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Caderno do Artigo","notebook-preview-download":"Baixar Caderno","notebook-preview-download-src":"Descarregar código fonte","notebook-preview-back":"Voltar ao Artigo","manuscript-meca-bundle":"Arquivo MECA","section-title-abstract":"Resumo","section-title-appendices":"Apêndices","section-title-footnotes":"Notas de rodapé","section-title-references":"Referências","section-title-reuse":"Reuso","section-title-copyright":"Direito autoral","section-title-citation":"Citação","appendix-attribution-cite-as":"Por favor, cite este trabalho como:","appendix-attribution-bibtex":"BibTeX","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Afiliação","title-block-affiliation-plural":"Afiliações","title-block-published":"Data de Publicação","title-block-modified":"Data de Modificação","title-block-keywords":"Palavras-chave","callout-tip-title":"Dica","callout-note-title":"Nota","callout-warning-title":"Aviso","callout-important-title":"Importante","callout-caution-title":"Cuidado","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar o código","code-tools-hide-all-code":"Esconder o código","code-tools-view-source":"Ver o código fonte","code-tools-source-code":"Código fonte","tools-share":"Share","tools-download":"Download","code-line":"Linha","code-lines":"Linhas","copy-button-tooltip":"Copiar para a área de transferência","copy-button-tooltip-success":"Copiada","repo-action-links-edit":"Editar essa página","repo-action-links-source":"Ver o código fonte","repo-action-links-issue":"Criar uma issue","back-to-top":"De volta ao topo","search-no-results-text":"Nenhum resultado","search-matching-documents-text":"documentos correspondentes","search-copy-link-title":"Copiar link para a busca","search-hide-matches-text":"Esconder correspondências adicionais","search-more-match-text":"mais correspondência neste documento","search-more-matches-text":"mais correspondências neste documento","search-clear-button-title":"Limpar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Procurar","toggle-section":"Alternar seção","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo escuro","toggle-reader-mode":"Alternar modo de leitor","toggle-navigation":"Alternar de navegação","crossref-fig-title":"Figura","crossref-tbl-title":"Tabela","crossref-lst-title":"Listagem","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolário","crossref-prp-title":"Proposição","crossref-cnj-title":"Conjetura","crossref-def-title":"Definição","crossref-exm-title":"Exemplo","crossref-exr-title":"Exercício","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apêndice","crossref-sec-prefix":"Seção","crossref-eq-prefix":"Equação","crossref-lof-title":"Lista de Figuras","crossref-lot-title":"Lista de Tabelas","crossref-lol-title":"Lista de Listagens","environment-proof-title":"Comprovação","environment-remark-title":"Comentário","environment-solution-title":"Solução","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Pré-selecionado","listing-page-order-by-date-asc":"Mais velho","listing-page-order-by-date-desc":"O mais novo","listing-page-order-by-number-desc":"Decrescente","listing-page-order-by-number-asc":"Crescente","listing-page-field-date":"Data","listing-page-field-title":"Título","listing-page-field-description":"Descrição","listing-page-field-author":"Autor","listing-page-field-filename":"Nome do arquivo","listing-page-field-filemodified":"Arquivo modificado","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tempo de leitura","listing-page-field-wordcount":"Contagem de Palavras","listing-page-field-categories":"Categorias","listing-page-minutes-compact":"{0} minutos","listing-page-category-all":"Tudo","listing-page-no-matches":"Nenhum item correspondente","listing-page-words":"{0} palavras"},"metadata":{"lang":"pt","fig-responsive":true,"quarto-version":"1.4.553","theme":{"dark":"darkly","light":"flatly"},"title":"Lista 3 - Econometria - ME715","crossref":{"eq-prefix":"Eq. "}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}